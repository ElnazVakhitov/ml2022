{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Первое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простое как пробка задание. Обучите классификатор [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) на входных данных с гиперпараметрами:\n",
    "\n",
    "* `max_depth`=$6$\n",
    "* `min_samples_split`=$3$\n",
    "* `min_samples_leaf`=$3$\n",
    "* `n_estimators`=$100$\n",
    "* `n_jobs`=$-1$\n",
    "\n",
    "И верните обученную модель.\n",
    "\n",
    "Данные в X только численные, в y только 2 значения: 0 и 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def fit_rf(X: np.ndarray, y:np.ndarray) ->  RandomForestClassifier:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Первая классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В [папке data](https://github.com/samstikhin/ml2021/tree/master/02-IntroML) вы можете найти данные для бинарной классификации (файл `diabets_train.csv` и `diabets_test.csv`). $Y$ в этих данных выступает столбик `Outcome`, в качестве $X$ - все остальное. \n",
    "\n",
    "Вам необходимо предсказать $y_{test}$ такой, что $accuracy > 0.75$ ([доля правильных ответов](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)). Вы можете делать что угодно, чтобы получить результат:\n",
    "\n",
    "* использовать любой классификатор с любыми гиперпараметрами\n",
    "* как угодно изменять данные \n",
    "\n",
    "Вернуть в этом случае нужно не модель, а результат - одномерный массив данных $y_{pred}$ (предсказание $y_{test}$).\n",
    "\n",
    "P.S. Можете узнать больше о данных по [ссылке](https://www.kaggle.com/uciml/pima-indians-diabetes-database). Мы произвольным образом разбили данные в соотношении 4:1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classification(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray) -> np.ndarray:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В [папке data](https://github.com/samstikhin/ml2021/tree/master/02-IntroML) вы можете найти данные для бинарной классификации (файлы `overfit_trian.csv`, `overfit_test.csv`). Вам на вход подается тренировочная и тестовая выборки из файла. \n",
    "\n",
    "Верните такую обученную модель, которая на тренировочной выборке дает $accuracy > 0.97$, а на тестовом $accuracy < 0.7$.\n",
    "\n",
    "[$accuracy$](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) - доля правильных ответов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def overfitting(X_train: np.array, y_train: np.array, X_test: np.array, y_test: np.array):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Мой KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача реализовать свой простой KNNClassifier для бинарных данных. Вам нужно реализовать 3 метода:\n",
    "\n",
    "* `init` - начальная инициализация\n",
    "* `fit` - обучение классификатора\n",
    "* `predict` - предсказание для новых объектов\n",
    "* `predict_proba` - предсказание вероятностей новых объектов\n",
    "\n",
    "У нашего классификатора будет лишь один гиперпараметр - количество соседей $k$. Во избежании тонкостей: $k$ - нечетное.\n",
    "\n",
    "На вход будет подаваться выборка объектов $X$, у которых ровно 2 числовых признака. $y$ - результат бинарной классификации $0$ или $1$.\n",
    "\n",
    "Метрика ближайших элементов - Эвклидова.\n",
    "\n",
    "Напоминание: $y$ - одномерный массив, $X$ - двумерный массив, по $0$-ой оси которой расположены объекты.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "X_train = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_train = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = KNN(k=3).fit(X_train, y_train)\n",
    "y_pred = model.predict(np.array([[0.5, 0.5], [ -0.5,  -0.5]]))\n",
    "y_prob = model.predict_proba(np.array([[0.5, 0.5], [-0.5, -0.5]]))\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = np.array([1., 0.])\n",
    "y_prob = np.array([[0.33, 0.667],\n",
    "                   [0.667, 0.33]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, k=3):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train:np.array): #обучаем классификатор\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.array): #предсказываем значения\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X_test: np.array): #предсказываем вероятности\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Моя Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вам предстоит реализовать свою простейшую линейную регрессию по функционалу $MSE$.\n",
    "\n",
    "Линейная регрессия выглядит следующим образом:\n",
    "$$a(x) = w_1x + w_0$$\n",
    "\n",
    "Необходимо найти такие $w_0$ и $w_1$, при которых минимизируется значение\n",
    "\n",
    "$$MSE(X,Y) = \\frac{1}{n}\\sum_{i=1}^{n}(a(x_i) - y_i)^2$$\n",
    "\n",
    "Выведите формулы для $w_0$ и $w_1$ аналитически и реализуйте следующие методы класса \n",
    "\n",
    "* `init` - начальная инициализация\n",
    "* `fit` - обучение классификатора\n",
    "* `predict` - предсказание для новых объектов\n",
    "\n",
    "После обучения у модели должен присутствовать атрибут `model.coef_` из которого можно получить коэффициенты регрессии в порядке: $w_1$, $w_0$.\n",
    "\n",
    "Гиперпараметры отсутствуют.\n",
    "\n",
    "На вход будут подаваться два массива $X\\in \\mathbb{R}^{n}$ и $Y \\in \\mathbb{R}^{n}$.\n",
    "\n",
    "Метрика - Евклидова.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "X_train = np.array([[1], [2]])\n",
    "y_train = np.array([1, 2])\n",
    "\n",
    "model = LinReg().fit(X_train, y_train)\n",
    "y_pred = model.predict(np.array([[3],[4]]))\n",
    "\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = np.array([3, 4])\n",
    "model.coef_ = np.array([1., 0.])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg():\n",
    "    def __init__(self):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train:np.array): #обучаем регрессию\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.array): #предсказываем значения\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Наивный (зато свой) Байес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется написать свой классификтор, на основе наивного баеса. Необходимо реализовать аналог `MultinomialNB`. \n",
    "\n",
    "$$y_{test} = argmax_{c}\\ln{P(y_{test}=c)} + \\sum_{j=1}^{m}\\ln{(P(f_j|y_{test}=c) + \\alpha)}, ~~~ c\\in\\{0,1\\}$$\n",
    "\n",
    "На вход подаются численные категориальные признаки. Классы: $0$ и $1$. У классификатора будет единственный параметр - $alpha$.\n",
    "\n",
    "### Sample 1:\n",
    "#### Input:\n",
    "```python\n",
    "X_clf = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_clf = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = MyNaiveBayes(alpha=1).fit(X_clf, y_clf)\n",
    "\n",
    "y_pred = model.predict(np.array([[1, 2], [-1, -2]]))\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = [1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "class MyNaiveBayes():\n",
    "    def __init__(self, alpha=1):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert X.ndim == 2\n",
    "        assert y.ndim == 1\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X: np.ndarray):\n",
    "        assert X.ndim == 2\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Злобные твиты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байес очень хорошо подходит для Анализа тональности текста. То есть определить несет текст позитивный или негативный вайб :) \n",
    "\n",
    "В данной задаче вам даны [твиты про разные авиакомпании](https://github.com/samstikhin/ml2021/tree/master/02-IntroML) (файлы `tweets_train.csv`, `tweets_test.csv`). Требуется построить классификатор, который бы определял имеет ли твит положительную или негативную окраску. Напишите функцию `predict`, который возвращает массив, где 1 - это позитивный, 0 - негативный. \n",
    "\n",
    "В данной задаче вам понадобятся `TweetTokenizer` и `CountVectorizer`. \n",
    "\n",
    "* `TweetTokenizer` и любой tokenizer самостоятельно разбивает строку на слова как-то их модифицировав.\n",
    "* `CountVectorizer` превращает предложение в вектор чисел основываясь на их частоте, используя токенайзер.\n",
    "\n",
    "Задача делится на 2 пункта: \n",
    "\n",
    "* Preprocessing: переведите все слова в нижний регистр, токенизируйте слова с помощью `TweetTokenizer`, а дальше опять соберите в предложение. Проделайте это и в $X_{train}$ и $X_{test}$\n",
    "* Predict: переведите предложения в вектора количеств с помощь `CountVectorizer`. Обучите модель на данных и предскажите ответ.\n",
    "\n",
    "Чтобы получить баллы надо побить accuracy = 0.88\n",
    "\n",
    "\n",
    "P.S Можете посмотреть топ слов, которые с наибольшей вероятностью относятся к позитивным и негативным классам. \n",
    "\n",
    "P.P.S. Если ничего не понятно: можете изучить различные kernel на [kaggle](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer, TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def predict(df_train: pd.DataFrame, df_test: pd.DataFrame):\n",
    "    \n",
    "    # preprocess data here\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    model = MultinomialNB ...\n",
    "        \n",
    "    # fit model\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    return model.predict(...) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
