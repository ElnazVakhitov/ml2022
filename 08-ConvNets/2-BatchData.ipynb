{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4 Распознавание цифр (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_libs import *\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "from torch.nn import Sequential, Linear, LogSoftmax, Sigmoid, Flatten, Softmax, ReLU\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Картинки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([1, 3, 7, 7, 9, 2, 4, 6, 8, 4, 4, 6, 7, 5, 9, 1, 9, 5, 2, 4, 7, 0, 7, 6,\n",
       "         1, 1, 9, 7, 3, 1, 1, 8])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596656c78ec941b590d2315ccf9092ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7beed9fcaf4a3782a426b53dfe8ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b03c60d8c2c41388ea8adeefdcead4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a486790b41444679dbd48703802bc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train, val = random_split(train_data, [55000, 5000])\n",
    "train_loader = DataLoader(train, batch_size=32)\n",
    "val_loader = DataLoader(val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[4][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(val[4][0].reshape(28,28).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.269879937171936, Accuracy: 0.6802363636363636\n",
      "Epoch: 2, Train Loss: 0.3911306858062744, Accuracy: 0.8904727272727273\n",
      "Epoch: 3, Train Loss: 0.31996259093284607, Accuracy: 0.9075636363636364\n",
      "Epoch: 4, Train Loss: 0.28463730216026306, Accuracy: 0.9178181818181819\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    Linear(28 * 28, 64), # на входе - размеры картинки\n",
    "    ReLU(),\n",
    "    Linear(64, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 10) # 10 классов\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Спуск\n",
    "for epoch in range(4):\n",
    "    \n",
    "    # training part\n",
    "    train_losses = list()\n",
    "    train_count_correct = 0 \n",
    "    for batch in train_loader: # 55000 / 32 раз\n",
    "        x, y = batch\n",
    "        # x: batch_size x 1 x 28 x 28\n",
    "        # y: batch_size x 1\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # matrix of vectors batch_size x (28 * 28)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        batch_loss = criterion(y_pred, y)\n",
    "        \n",
    "        train_losses.append(batch_loss.item())\n",
    "        train_count_correct += (y_pred.argmax(-1) == y).sum().item()\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1}, Train Loss: {torch.tensor(train_losses).mean()}, Accuracy: {train_count_correct / len(train)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.28182294964790344, Test Accuracy: 0.9194\n"
     ]
    }
   ],
   "source": [
    "val_losses = list()\n",
    "val_count_correct = 0\n",
    "for batch in val_loader:\n",
    "    x, y = batch\n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x) \n",
    "\n",
    "    batch_loss = criterion(y_pred, y)\n",
    "    val_losses.append(batch_loss.item())\n",
    "    val_count_correct += (y_pred.argmax(-1) == y).sum().item()\n",
    "\n",
    "print(f'Test Loss: {torch.tensor(val_losses).mean()}, Test Accuracy: {val_count_correct / len(val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обычно делают одновременно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.212336540222168, Accuracy: 0.6834727272727272\n",
      "Epoch: 1, Test Loss: 0.5203611254692078, Accuracy: 0.8592\n",
      "------------------------------------\n",
      "Epoch: 2, Train Loss: 0.4020938575267792, Accuracy: 0.8878\n",
      "Epoch: 2, Test Loss: 0.3696366250514984, Accuracy: 0.8992\n",
      "------------------------------------\n",
      "Epoch: 3, Train Loss: 0.32035088539123535, Accuracy: 0.9084363636363636\n",
      "Epoch: 3, Test Loss: 0.31972256302833557, Accuracy: 0.9096\n",
      "------------------------------------\n",
      "Epoch: 4, Train Loss: 0.2810913324356079, Accuracy: 0.9192545454545454\n",
      "Epoch: 4, Test Loss: 0.2877568304538727, Accuracy: 0.9184\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    Linear(28 * 28, 64), # на входе - размеры картинки\n",
    "    ReLU(),\n",
    "    Linear(64, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 10) # 10 классов\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Спуск\n",
    "for epoch in range(4):\n",
    "    \n",
    "    # training part\n",
    "    train_losses = list()\n",
    "    train_count_correct = 0 \n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        # x: batch_size x 1 x 28 x 28\n",
    "        # y: batch_size x 1\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        y_pred = model(x) \n",
    "        \n",
    "        batch_loss = criterion(y_pred, y)\n",
    "        train_losses.append(batch_loss.item())\n",
    "        train_count_correct += (y_pred.argmax(-1) == y).sum().item()\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1}, Train Loss: {torch.tensor(train_losses).mean()}, Accuracy: {train_count_correct / len(train)}')\n",
    "    \n",
    "    # validation part\n",
    "    val_losses = list()\n",
    "    val_count_correct = 0\n",
    "    for batch in val_loader:\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x) \n",
    "        \n",
    "        batch_loss = criterion(y_pred, y)\n",
    "        val_losses.append(batch_loss.item())\n",
    "        val_count_correct += (y_pred.argmax(-1) == y).sum().item()\n",
    "\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1}, Test Loss: {torch.tensor(val_losses).mean()}, Accuracy: {val_count_correct / len(val)}')\n",
    "    print('------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки интересные\n",
    "* [MNIST solution](https://www.youtube.com/watch?v=OMDn66kM9Qc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
